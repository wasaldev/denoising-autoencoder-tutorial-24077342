# -*- coding: utf-8 -*-
"""Machine Learning Tutorial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dso5lU-Gog-JH1OulHDpYNRtWxZErztC

## **Course Name: 7PAM2021-0901-2025 - Machine Learning and Neural Networks**
### **Name: Muhammad Wasal Imtiaz**
### **Student ID: 24077342**

# **Tutorial: Denoising Autoencoders for Image Reconstruction**

Welcome to this practical tutorial for the **Machine Learning and Neural Networks** module. In this session, we will explore how neural networks can be used to learn robust representations of data by introducing and implementing **Denoising Autoencoders**.

Denoising Autoencoders are a powerful form of unsupervised learning, designed to reconstruct clean data from corrupted inputs. By intentionally adding noise to a dataset such as handwritten digits from the MNIST dataset, we can train a model that learns to ignore irrelevant variations and recover the underlying structure of the data.

In this tutorial, you will:

- Build a denoising autoencoder using the Keras deep learning framework.  
- Train the model on the MNIST dataset of handwritten digits.
- Add controlled noise to the input images to simulate real world data corruption.
- Compare original, noisy, and reconstructed outputs visually.
- Generate plots and reconstruction examples for inclusion in the accompanying PDF report.

By the end of this notebook, you will have a deeper understanding of how autoencoders extract meaningful, low dimensional representations and how denoising improves their ability to generalise beyond the input data.

## Imports & Reproducibility
"""

# Adding Imports

import numpy as np
import matplotlib.pyplot as plt

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping

# Set random seeds for reproducibility
np.random.seed(42)
import tensorflow as tf
tf.random.set_seed(42)

"""## Load MNIST Dataset"""

# Loading the MNIST dataset
# We only need the images (x_train, x_test); labels are not used for autoencoders.

(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()

print("Training set shape:", x_train.shape)
print("Test set shape:", x_test.shape)

"""## Preprocess: Normalise & Reshape"""

# Preprocessing: scale pixels to [0, 1] and add channel dimension

# Convert to float32 and scale from [0, 255] → [0, 1]
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# Add a channel dimension so the shape becomes (28, 28, 1)
x_train = np.expand_dims(x_train, axis=-1)
x_test = np.expand_dims(x_test, axis=-1)

print("Training set reshaped:", x_train.shape)
print("Test set reshaped:", x_test.shape)

"""## Add Gaussian Noise"""

# Adding Gaussian noise to the images
# The model will see noisy inputs but is trained to reconstruct the clean images.

noise_factor = 0.2  # If this is too high, digits become unreadable and the task is impossible.

# Add Gaussian noise with mean 0 and standard deviation 1
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)

# Clip to maintain valid pixel range [0, 1]
x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

print("Noisy training set shape:", x_train_noisy.shape)
print("Noisy test set shape:", x_test_noisy.shape)

"""## Visualise Original vs Noisy"""

# Visualising a few original vs noisy examples

def show_noisy_examples(x_clean, x_noisy, n=10):
    """Display n original images (top row) and their noisy versions (bottom row)."""
    plt.figure(figsize=(20, 4))
    for i in range(n):
        # Original
        ax = plt.subplot(2, n, i + 1)
        plt.imshow(x_clean[i].squeeze(), cmap="gray", vmin=0, vmax=1)
        plt.title("Original")
        plt.axis("off")

        # Noisy
        ax = plt.subplot(2, n, i + 1 + n)
        plt.imshow(x_noisy[i].squeeze(), cmap="gray", vmin=0, vmax=1)
        plt.title("Noisy")
        plt.axis("off")
    plt.tight_layout()
    plt.show()

show_noisy_examples(x_test, x_test_noisy, n=10)

"""## Build the Denoising Autoencoder"""

# Building the convolutional denoising autoencoder

input_shape = (28, 28, 1)

# Input layer for 28x28 grayscale images
input_img = keras.Input(shape=input_shape, name="input_image")

# ----- Encoder -----
# First convolution + pooling: extract low-level features and downsample
x = layers.Conv2D(32, (3, 3), activation="relu", padding="same")(input_img)
x = layers.MaxPooling2D((2, 2), padding="same")(x)   # -> 14x14

# Second convolution + pooling: deeper features, smaller spatial size
x = layers.Conv2D(64, (3, 3), activation="relu", padding="same")(x)
x = layers.MaxPooling2D((2, 2), padding="same")(x)   # -> 7x7

# Latent representation (bottleneck)
latent = layers.Conv2D(64, (3, 3), activation="relu", padding="same", name="latent")(x)

# ----- Decoder -----
# Mirror the encoder: upsample back to original resolution
x = layers.Conv2D(64, (3, 3), activation="relu", padding="same")(latent)
x = layers.UpSampling2D((2, 2))(x)                   # -> 14x14

x = layers.Conv2D(32, (3, 3), activation="relu", padding="same")(x)
x = layers.UpSampling2D((2, 2))(x)                   # -> 28x28

# Final reconstruction layer.
# Sigmoid ensures outputs lie in [0, 1], matching our normalised pixel range.
decoded = layers.Conv2D(1, (3, 3), activation="sigmoid", padding="same", name="output_image")(x)

# Full autoencoder model: maps noisy images to reconstructed clean images
autoencoder = keras.Model(input_img, decoded, name="denoising_autoencoder")

autoencoder.summary()

"""## Compile the Model"""

# Compiling the model
# Because the outputs are in [0, 1], binary cross-entropy works well for this reconstruction task.

autoencoder.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-3),
    loss="binary_crossentropy",
    metrics=["mse"]  # track mean squared error as an additional metric
)

"""## Train the Model with Early Stopping"""

# Training the denoising autoencoder

epochs = 50
batch_size = 128

# Early stopping stops training if validation loss does not improve for 5 epochs
early_stop = EarlyStopping(
    monitor="val_loss",
    patience=5,
    restore_best_weights=True
)

history = autoencoder.fit(
    x_train_noisy, x_train,              # noisy input → clean target
    epochs=epochs,
    batch_size=batch_size,
    shuffle=True,
    validation_data=(x_test_noisy, x_test),
    callbacks=[early_stop]
)

"""## Plot Training & Validation Loss"""

# Plotting the training and validation loss curves

def plot_history(history):
    plt.figure(figsize=(8, 4))
    plt.plot(history.history["loss"], label="Train Loss")
    plt.plot(history.history["val_loss"], label="Val Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Binary Cross-Entropy Loss")
    plt.title("Denoising Autoencoder Training Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

plot_history(history)

"""## Generate Denoised Reconstructions"""

# Using the trained model to reconstruct (denoise) the test images

decoded_imgs = autoencoder.predict(x_test_noisy)

print("Decoded images shape:", decoded_imgs.shape)

"""## Visualise Original vs Noisy vs Denoised"""

# Visual comparison: Original vs Noisy vs Denoised

def show_denoising_results(x_clean, x_noisy, x_decoded, n=10):
    """
    Display n samples in three rows:
    - Top: original clean images
    - Middle: noisy corrupted images
    - Bottom: denoised reconstructions from the autoencoder
    """
    plt.figure(figsize=(20, 6))
    for i in range(n):
        # Original
        ax = plt.subplot(3, n, i + 1)
        plt.imshow(x_clean[i].squeeze(), cmap="gray", vmin=0, vmax=1)
        plt.title("Original")
        plt.axis("off")

        # Noisy
        ax = plt.subplot(3, n, i + 1 + n)
        plt.imshow(x_noisy[i].squeeze(), cmap="gray", vmin=0, vmax=1)
        plt.title("Noisy")
        plt.axis("off")

        # Denoised
        ax = plt.subplot(3, n, i + 1 + 2 * n)
        plt.imshow(x_decoded[i].squeeze(), cmap="gray", vmin=0, vmax=1)
        plt.title("Denoised")
        plt.axis("off")

    plt.tight_layout()
    plt.show()

show_denoising_results(x_test, x_test_noisy, decoded_imgs, n=10)

"""## Latent Space & Saving Outputs"""

# Inspect latent representations and save outputs

# Build a separate encoder model to access the latent space
encoder = keras.Model(autoencoder.input, autoencoder.get_layer("latent").output, name="encoder_model")
encoder.summary()

# Get latent representations for a subset of test images
latent_repr = encoder.predict(x_test[:1000])
print("Latent representation shape:", latent_repr.shape)

# Save arrays for later use
np.save("x_test_original.npy", x_test)
np.save("x_test_noisy.npy", x_test_noisy)
np.save("x_test_denoised.npy", decoded_imgs)

"""# Latent Feature Visualisation"""

# Visualising latent feature maps for one test image

print("Latent representation shape:", latent_repr.shape)

sample_index = 0      # which test image to inspect
num_feature_maps = 8  # how many channels to display

feature_maps = latent_repr[sample_index]  # shape: (7, 7, 64)

plt.figure(figsize=(14, 3))
for i in range(num_feature_maps):
    ax = plt.subplot(1, num_feature_maps, i + 1)
    plt.imshow(feature_maps[:, :, i], cmap="viridis")
    plt.title(f"Map {i+1}")
    plt.axis("off")
print('\n')
plt.suptitle("Latent Feature Visualisation", y=1.05, fontsize=12)
plt.tight_layout()
plt.show()
print('\n')

